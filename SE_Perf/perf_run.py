#!/usr/bin/env python3
"""
PerfAgent é›†æˆæ‰§è¡Œè„šæœ¬

åŠŸèƒ½ï¼š
    åœ¨ SE æ¡†æ¶ä¸­é©±åŠ¨ PerfAgent è¿›è¡Œå•æ¬¡æˆ–å¤šæ¬¡è¿­ä»£çš„æ€§èƒ½ä¼˜åŒ–ã€‚
    æ¨¡ä»¿ SE/basic_run.py çš„ç»“æ„ï¼Œæ”¯æŒç­–ç•¥é©±åŠ¨çš„æ‰§è¡Œæµç¨‹ã€‚
"""

import argparse
import json
import math
import os
import shutil
import subprocess
import sys
import tempfile
from datetime import datetime
from pathlib import Path
from typing import Any

import yaml

# æ·»åŠ  SE æ ¹ç›®å½•åˆ° Python è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent))

# å¯¼å…¥ SE æ ¸å¿ƒæ¨¡å—
from core.global_memory.utils.config import GlobalMemoryConfig
from core.utils.global_memory_manager import GlobalMemoryManager
from core.utils.local_memory_manager import LocalMemoryManager
from core.utils.se_logger import get_se_logger, setup_se_logging
from core.utils.traj_extractor import TrajExtractor
from core.utils.traj_pool_manager import TrajPoolManager
from core.utils.trajectory_processor import TrajectoryProcessor
from operators import create_operator
from perf_config import LocalMemoryConfig, PerfRunCLIConfig, SEPerfRunSEConfig

from perfagent.run import load_instance_data

# --- è¾…åŠ©å‡½æ•° ---


def _execute_operator_step(
    step_config: dict[str, Any],
    se_config: dict[str, Any],
    traj_pool_manager: TrajPoolManager,
    workspace_dir: str,
    logger,
) -> dict[str, Any]:
    """
    æ‰§è¡Œå•ä¸ªç®—å­æ­¥éª¤ã€‚

    Args:
        step_config: ç®—å­æ­¥éª¤é…ç½®
        se_config: SE å…¨å±€é…ç½®
        traj_pool_manager: è½¨è¿¹æ± ç®¡ç†å™¨
        workspace_dir: å·¥ä½œç›®å½•
        logger: æ—¥å¿—è®°å½•å™¨

    Returns:
        ç®—å­æ‰§è¡Œç»“æœå­—å…¸
    """
    operator_name = step_config.get("operator")
    if not operator_name:
        logger.error("ç®—å­æ‰§è¡Œé”™è¯¯ï¼šæ­¥éª¤é…ç½®ç¼ºå°‘ 'operator' å­—æ®µ")
        return {}

    # åˆå¹¶é…ç½®ï¼šä¼˜å…ˆä½¿ç”¨ step_config ä¸­çš„è®¾ç½®ï¼Œå…¶æ¬¡æ˜¯ se_config
    operator_config = dict(se_config) if isinstance(se_config, dict) else {}

    if step_config.get("selection_mode"):
        operator_config["operator_selection_mode"] = step_config.get("selection_mode")
    if step_config.get("prompt_config"):
        operator_config["prompt_config"] = step_config.get("prompt_config")

    operator_instance = create_operator(operator_name, operator_config)
    if not operator_instance:
        logger.error(f"æ— æ³•åˆ›å»ºç®—å­å®ä¾‹: {operator_name}")
        return {}

    result = {}
    try:
        result = operator_instance.run(step_config, traj_pool_manager, workspace_dir)
    except Exception as e:
        logger.error(f"ç®—å­ '{operator_name}' æ‰§è¡Œå¤±è´¥: {e}")
        return {}

    # è®°å½•ç»“æœæ—¥å¿—
    initial_code_path = result.get("initial_code_dir")
    if isinstance(initial_code_path, str) and initial_code_path:
        path_obj = Path(initial_code_path)
        if path_obj.exists():
            logger.info(f"ç®—å­è¿”å›åˆå§‹ä»£ç ç›®å½•: {path_obj}")

    generated_count = result.get("generated_count")
    if generated_count is not None:
        try:
            logger.info(f"ç®—å­ç”Ÿæˆåˆå§‹ä»£ç æ•°é‡: {int(generated_count)}")
        except (ValueError, TypeError):
            pass

    return result


def _summarize_iteration_to_pool(
    iteration_dir: Path,
    iteration_index: int,
    traj_pool_manager: TrajPoolManager,
    se_config: dict[str, Any],
    logger,
    label_prefix: str | None = None,
    source_labels_map: dict[str, list[str]] | None = None,
    operator_name: str | None = None,
) -> None:
    """
    æå–è¿­ä»£ç»“æœå¹¶æ›´æ–°åˆ°è½¨è¿¹æ± ã€‚
    """
    try:
        # æ›´æ–° prompt_config
        prompt_config = se_config.get("prompt_config")
        if isinstance(prompt_config, dict):
            traj_pool_manager.prompt_config = prompt_config

        extractor = TrajExtractor()
        # æå–å®ä¾‹æ•°æ®ï¼ŒåŒ…å«æ€§èƒ½æŒ‡æ ‡
        extracted_data = extractor.extract_instance_data(iteration_dir, include_metrics=True)

        if not extracted_data:
            logger.warning(f"è¿­ä»£ {iteration_index}ï¼šæ²¡æœ‰æœ‰æ•ˆçš„å®ä¾‹æ•°æ®ç”¨äºè½¨è¿¹æ± æ€»ç»“")
            return

        trajectories_to_process = []
        for item in extracted_data:
            # å…¼å®¹æ—§æ ¼å¼è§£åŒ…
            if len(item) == 5:
                instance_name, problem_desc, tra_content, patch_content, perf_metrics = item
            else:
                instance_name, problem_desc, tra_content, patch_content = item
                perf_metrics = None

            label = str(label_prefix) if label_prefix else f"iter{iteration_index}"

            # è·å–æºæ ‡ç­¾
            instance_source_labels = None
            if source_labels_map and isinstance(source_labels_map, dict):
                instance_source_labels = source_labels_map.get(str(instance_name))

            trajectories_to_process.append(
                {
                    "label": label,
                    "instance_name": instance_name,
                    "problem_description": problem_desc,
                    "trajectory_content": tra_content,
                    "patch_content": patch_content,
                    "iteration": iteration_index,
                    "performance": (perf_metrics or {}).get("performance"),
                    "source_dir": str(iteration_dir / instance_name),
                    "source_entry_labels": list(instance_source_labels or []),
                    "operator_name": str(operator_name) if operator_name else None,
                    "perf_metrics": perf_metrics,
                }
            )

        traj_pool_manager.summarize_and_add_trajectories(
            trajectories_to_process, num_workers=se_config.get("num_workers")
        )

        pool_stats = traj_pool_manager.get_pool_stats()
        logger.info(f"è½¨è¿¹æ± æ›´æ–°å®Œæ¯•: å½“å‰å…± {pool_stats.get('total_trajectories', 'unknown')} æ¡è½¨è¿¹")

    except Exception as e:
        logger.error(f"è¿­ä»£è½¨è¿¹æ± æ›´æ–°å¤±è´¥: {e}")


def _extract_optimization_info(perf_config_path: str | None) -> tuple[str | None, str | None]:
    """
    ä» PerfAgent é…ç½®æ–‡ä»¶ä¸­æå–ä¼˜åŒ–ç›®æ ‡å’Œè¯­è¨€é…ç½®ã€‚
    """
    if not perf_config_path:
        return None, None

    try:
        with open(perf_config_path, encoding="utf-8") as f:
            config = yaml.safe_load(f) or {}

        opt_target = config.get("optimization", {}).get("target")
        language = config.get("language_cfg", {}).get("language")

        target_str = str(opt_target) if isinstance(opt_target, str) and opt_target.strip() else None
        language_str = str(language) if isinstance(language, str) and language.strip() else None

        return target_str, language_str
    except Exception:
        return None, None


def write_iteration_preds(base_dir: Path, logger) -> Path | None:
    """
    èšåˆå½“å‰è¿­ä»£å„å®ä¾‹çš„ç»“æœï¼Œç”Ÿæˆ preds.jsonã€‚
    """
    predictions = {}
    try:
        for instance_dir in base_dir.iterdir():
            if not instance_dir.is_dir():
                continue

            result_file = instance_dir / "result.json"
            if not result_file.exists():
                continue

            try:
                with open(result_file, encoding="utf-8") as f:
                    data = json.load(f)
            except Exception:
                continue

            instance_id = data.get("instance_id", instance_dir.name)
            code = data.get("optimized_code", "")
            final_perf = data.get("final_performance")
            final_metrics = data.get("final_metrics") or {}

            # åªè¦ final_perf ä¸æ˜¯æ— ç©·å¤§ï¼Œå°±è®¤ä¸ºé€šè¿‡
            is_passed = False
            if final_perf is not None:
                try:
                    is_passed = not math.isinf(float(final_perf))
                except (ValueError, TypeError):
                    is_passed = False

            predictions[str(instance_id)] = {
                "code": code,
                "passed": is_passed,
                "performance": final_perf,
                "final_metrics": final_metrics,
            }

        preds_path = base_dir / "preds.json"
        with open(preds_path, "w", encoding="utf-8") as f:
            json.dump(predictions, f, indent=2, ensure_ascii=False)

        logger.info(f"å·²ç”Ÿæˆè¿­ä»£é¢„æµ‹æ±‡æ€»: {preds_path}")
        return preds_path

    except Exception as e:
        logger.warning(f"ç”Ÿæˆ preds.json å¤±è´¥: {e}")
        return None


def aggregate_all_iterations_preds(root_output_dir: Path, logger) -> Path | None:
    """
    æ±‡æ€»æ‰€æœ‰ iteration_* ç›®å½•ä¸‹çš„ preds.json åˆ°æ ¹ç›®å½•ã€‚
    """
    aggregated_data: dict[str, list[dict]] = {}

    try:
        # éå†æ‰€æœ‰è¿­ä»£ç›®å½•ï¼ŒæŒ‰æ•°å­—é¡ºåºæ’åº
        iteration_dirs = sorted(root_output_dir.glob("iteration_*"), key=lambda p: p.name)

        for iter_dir in iteration_dirs:
            if not iter_dir.is_dir():
                continue

            # è§£æè¿­ä»£å·
            try:
                iter_num = int(iter_dir.name.split("_")[-1])
            except ValueError:
                continue

            preds_file = iter_dir / "preds.json"
            if not preds_file.exists():
                continue

            try:
                with open(preds_file, encoding="utf-8") as f:
                    preds = json.load(f)
            except Exception:
                continue

            for instance_id, info in preds.items():
                try:
                    passed = bool(info.get("passed", False))
                    # æœªé€šè¿‡çš„å®ä¾‹ï¼Œcode ç½®ä¸ºç©ºå­—ç¬¦ä¸²
                    code = info.get("code", "") if passed else ""
                    performance = info.get("performance")
                    metrics_val = info.get("final_metrics")

                    # è‹¥ç¼ºå°‘ metricsï¼Œå°è¯•ä»è¯¥è¿­ä»£çš„ result.json å›é€€è¯»å–
                    try:
                        if not isinstance(metrics_val, dict) or not metrics_val:
                            res_path = Path(iter_dir) / str(instance_id) / "result.json"
                            if res_path.exists():
                                with open(res_path, encoding="utf-8") as rf:
                                    rj = json.load(rf)
                                fm = rj.get("final_metrics")
                                if isinstance(fm, dict):
                                    metrics_val = fm
                    except Exception:
                        pass

                    entry = {
                        "iteration": iter_num,
                        "code": code,
                        "performance": performance,
                        "final_metrics": metrics_val,
                    }
                    aggregated_data.setdefault(str(instance_id), []).append(entry)
                except Exception:
                    continue

        agg_path = root_output_dir / "preds.json"
        with open(agg_path, "w", encoding="utf-8") as f:
            json.dump(aggregated_data, f, indent=2, ensure_ascii=False)

        if logger:
            logger.info(f"æ±‡æ€»æ‰€æœ‰è¿­ä»£é¢„æµ‹ç»“æœ: {agg_path}")
        else:
            print(f"æ±‡æ€»æ‰€æœ‰è¿­ä»£é¢„æµ‹ç»“æœ: {agg_path}")
        return agg_path

    except Exception as e:
        if logger:
            logger.warning(f"æ±‡æ€» preds.json å¤±è´¥: {e}")
        else:
            print(f"æ±‡æ€» preds.json å¤±è´¥: {e}")
        return None


def write_final_json_from_preds(aggregated_preds_path: Path, root_output_dir: Path, logger) -> Path | None:
    """
    ä»æ±‡æ€»çš„ preds.json ä¸­é€‰æ‹©æœ€ä½³ç»“æœï¼ˆruntime æœ€å°ï¼‰å†™å…¥ final.jsonã€‚
    """
    try:
        with open(aggregated_preds_path, encoding="utf-8") as f:
            aggregated_data = json.load(f)
    except Exception as e:
        logger.warning(f"è¯»å–æ±‡æ€» preds.json å¤±è´¥: {e}")
        return None

    def _parse_runtime(rt_val):
        """è§£æ runtime å€¼ï¼Œå¼‚å¸¸æƒ…å†µè¿”å›æ— ç©·å¤§"""
        try:
            if rt_val is None:
                return float("inf")
            if isinstance(rt_val, (int, float)):
                return float(rt_val)
            if isinstance(rt_val, str):
                lowered = rt_val.strip().lower()
                if lowered in ("inf", "infinity", "nan"):
                    return float("inf")
                return float(rt_val)
            return float("inf")
        except Exception:
            return float("inf")

    final_result_map: dict[str, str] = {}

    try:
        for instance_id, entries in aggregated_data.items():
            if not isinstance(entries, list) or not entries:
                continue

            # æ‰¾åˆ° runtime æœ€å°çš„æ¡ç›®
            try:
                best_entry = min(entries, key=lambda e: _parse_runtime(e.get("performance", e.get("runtime"))))
            except ValueError:
                continue

            final_result_map[str(instance_id)] = best_entry.get("code", "") or ""

        final_path = root_output_dir / "final.json"
        with open(final_path, "w", encoding="utf-8") as f:
            json.dump(final_result_map, f, indent=2, ensure_ascii=False)

        if logger:
            logger.info(f"ç”Ÿæˆæœ€ç»ˆç»“æœ final.json: {final_path}")
        return final_path

    except Exception as e:
        if logger:
            logger.warning(f"ç”Ÿæˆ final.json å¤±è´¥: {e}")
        else:
            print(f"ç”Ÿæˆ final.json å¤±è´¥: {e}")
        return None


def create_temp_perf_config(
    base_config_path: str | None,
    se_model_config: dict[str, Any],
    logger,
    extra_overrides: dict[str, Any] | None = None,
) -> Path | None:
    """
    ç”Ÿæˆä¸´æ—¶çš„ PerfAgent é…ç½®æ–‡ä»¶ã€‚
    """
    try:
        perf_config = {}
        if base_config_path:
            try:
                with open(base_config_path, encoding="utf-8") as f:
                    perf_config = yaml.safe_load(f) or {}
            except Exception as e:
                logger.warning(f"æ— æ³•è¯»å–åŸºç¡€é…ç½®æ–‡ä»¶ {base_config_path}: {e}")

        # æ¨¡å‹å‚æ•°è¦†ç›–ç™½åå•
        allowed_model_keys = {"name", "api_base", "api_key", "max_input_tokens", "max_output_tokens", "temperature"}

        model_overrides = {
            k: v
            for k, v in (se_model_config or {}).items()
            if k in allowed_model_keys and v is not None and str(v).strip() != ""
        }

        perf_config.setdefault("model", {}).update(model_overrides)

        # å…¶ä»–é¡¶å±‚å‚æ•°è¦†ç›–ï¼ˆå¦‚ max_iterationsï¼‰
        if extra_overrides:
            for key, val in extra_overrides.items():
                if val is not None and str(val).strip() != "":
                    # å°è¯•è½¬ä¸º intï¼Œå¦‚æœå¤±è´¥åˆ™ä¿æŒåŸå€¼
                    if key == "max_iterations":
                        try:
                            perf_config[key] = int(val)
                        except (ValueError, TypeError):
                            perf_config[key] = val
                    else:
                        perf_config[key] = val

        # å†™å…¥ä¸´æ—¶æ–‡ä»¶
        with tempfile.NamedTemporaryFile("w", suffix=".yaml", delete=False) as tmp_file:
            yaml.safe_dump(perf_config, tmp_file, sort_keys=False, allow_unicode=True)
            temp_path = Path(tmp_file.name)

        logger.info(f"ç”Ÿæˆä¸´æ—¶ PerfAgent é…ç½®: {temp_path}")
        logger.debug(f"æ¨¡å‹è¦†ç›–å‚æ•°: {json.dumps(model_overrides, ensure_ascii=False)}")

        return temp_path

    except Exception as e:
        logger.warning(f"ç”Ÿæˆä¸´æ—¶é…ç½®å¤±è´¥: {e}")
        return None


def call_perfagent(iteration_params: dict[str, Any], logger, dry_run: bool = False) -> dict[str, Any]:
    """
    è°ƒç”¨ PerfAgent æ‰§è¡Œæ‰¹é‡ä¼˜åŒ–ã€‚
    """
    base_config_path = iteration_params.get("perf_base_config")
    output_dir = Path(iteration_params["output_dir"]).resolve()
    instances_dir = iteration_params.get("instances_dir")
    num_workers = iteration_params.get("num_workers", 1)

    # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
    output_dir.mkdir(parents=True, exist_ok=True)

    try:
        # ç”Ÿæˆä¸´æ—¶é…ç½®
        se_model_config = iteration_params.get("model") or {}
        temp_config_path = create_temp_perf_config(
            base_config_path,
            se_model_config,
            logger,
            extra_overrides={
                "max_iterations": iteration_params.get("max_iterations"),
            },
        )

        # æ„å»ºå‘½ä»¤
        cmd = [sys.executable, "-m", "perfagent.run_batch"]

        # é…ç½®æ–‡ä»¶ï¼ˆä¼˜å…ˆä½¿ç”¨ä¸´æ—¶ç”Ÿæˆçš„ï¼‰
        config_path_to_use = temp_config_path if temp_config_path else base_config_path
        if config_path_to_use:
            cmd.extend(["--config", str(config_path_to_use)])

        cmd.extend(
            [
                "--instances-dir",
                str(instances_dir),
                "--base-dir",
                str(output_dir),
                "--max-workers",
                str(num_workers),
            ]
        )

        # ç®—å­ä¼ é€’çš„å‚æ•°
        operator_params = iteration_params.get("operator_params") or {}
        initial_code_dir = operator_params.get("initial_code_dir")
        instance_templates_dir = operator_params.get("instance_templates_dir")

        if initial_code_dir:
            cmd.extend(["--initial-code-dir", str(initial_code_dir)])
        if instance_templates_dir:
            cmd.extend(["--instance-templates-dir", str(instance_templates_dir)])

        cmd_str = " ".join(cmd)

        if dry_run:
            logger.info("æ¼”ç¤ºæ¨¡å¼ï¼šè·³è¿‡å®é™…æ‰§è¡Œ")
            print(f"ğŸš€ [DEMO] PerfAgent å‘½ä»¤é¢„è§ˆ: {cmd_str}")
            return {"status": "skipped", "reason": "dry_run", "preview_cmd": cmd_str}

        logger.info(f"æ‰§è¡Œ PerfAgent å‘½ä»¤: {cmd_str}")
        print(f"ğŸš€ æ‰§è¡Œ PerfAgent: {cmd_str}")

        # æ‰§è¡Œå‘½ä»¤
        result = subprocess.run(cmd, cwd=str(Path(__file__).parent.parent), text=True)

        if result.returncode == 0:
            logger.info("PerfAgent æ‰§è¡ŒæˆåŠŸ")
            print("âœ… PerfAgent æ‰§è¡ŒæˆåŠŸ")
            # ç”Ÿæˆå½“å‰è¿­ä»£çš„é¢„æµ‹ç»“æœ
            preds_path = write_iteration_preds(output_dir, logger)
            return {
                "status": "success",
                "summary": "success",
                "base_dir": str(output_dir),
                "preds_file": str(preds_path) if preds_path else None,
            }
        else:
            logger.error(f"PerfAgent æ‰§è¡Œå¤±è´¥ï¼Œè¿”å›ç : {result.returncode}")
            print(f"âŒ PerfAgent æ‰§è¡Œå¤±è´¥ï¼Œè¿”å›ç : {result.returncode}")
            return {"status": "failed", "returncode": result.returncode}

    except Exception as e:
        logger.error(f"è°ƒç”¨ PerfAgent å¼‚å¸¸: {e}", exc_info=True)
        return {"status": "error", "exception": str(e)}
    finally:
        # è¿™é‡Œå¯ä»¥æ·»åŠ åˆ é™¤ä¸´æ—¶é…ç½®æ–‡ä»¶çš„é€»è¾‘ï¼Œå¦‚æœéœ€è¦çš„è¯
        pass


# --- è¾…åŠ©å‡½æ•° ---


def _inject_global_memory(
    instance_reqs: dict,  # {inst_name: additional_reqs}
    global_memory: GlobalMemoryManager,
    local_memory_text: str | None,
    sys_prompt_dir: Path,
    base_config_path: str | None,
    se_config: dict,
    logger,
):
    """
    ä¸ºæ¯ä¸ªå®ä¾‹æ£€ç´¢ Global Memoryï¼Œå¹¶å†™å…¥åˆ° system prompt yaml æ–‡ä»¶ä¸­ã€‚
    """
    if not global_memory:
        return

    logger.info("å¼€å§‹æ£€ç´¢ Global Memory...")

    # å°è¯•ä» base_config è¯»å–é»˜è®¤é…ç½®
    default_lang = "python3"
    default_target = "runtime"

    if base_config_path:
        try:
            with open(base_config_path, encoding="utf-8") as f:
                bc = yaml.safe_load(f) or {}
                default_lang = bc.get("language_cfg", {}).get("language", default_lang)
                default_target = bc.get("optimization", {}).get("target", default_target)
        except Exception:
            pass

    instances_dir = Path(se_config.get("instances", {}).get("instances_dir", ""))
    instances_map = {}
    if instances_dir.exists():
        for fp in instances_dir.glob("*.json"):
            try:
                inst = load_instance_data(fp)
                key = fp.stem
                problem_text = inst.description_md or ""
                instances_map[str(key)] = problem_text or ""
            except Exception:
                pass

    for inst_name in instance_reqs.keys():  # instance_reqs key æ˜¯å®ä¾‹å
        try:
            req_text = instance_reqs[inst_name]
            desc = instances_map.get(str(inst_name), "")

            # æ„é€ ä¸Šä¸‹æ–‡ç”¨äºç”Ÿæˆ Query
            context = {
                "language": default_lang,
                "optimization_target": default_target,
                "problem_description": desc,
                "additional_requirements": req_text,
                "local_memory": local_memory_text or "",
            }

            # 1. ç”Ÿæˆ Query
            queries = global_memory.generate_queries(context)
            if not queries:
                continue

            # 2. æ£€ç´¢å¹¶åœ¨æ£€ç´¢é˜¶æ®µè¿›è¡Œç›¸å…³æ€§ç­›é€‰
            mem_content = global_memory.retrieve(queries, context=context)
            if not mem_content:
                continue

            # 3. å†™å…¥ YAML
            yaml_path = sys_prompt_dir / f"{inst_name}.yaml"
            data = {}
            if yaml_path.exists():
                with open(yaml_path, encoding="utf-8") as f:
                    data = yaml.safe_load(f) or {}

            pm = data.setdefault("prompts", {})
            pm["global_memory"] = mem_content

            with open(yaml_path, "w", encoding="utf-8") as f:
                yaml.safe_dump(data, f, allow_unicode=True, sort_keys=False)

        except Exception as e:
            logger.warning(f"å®ä¾‹ {inst_name} Global Memory æ³¨å…¥å¤±è´¥: {e}")


def _process_and_summarize(
    iter_dir: Path,
    iter_idx: int,
    step_config: dict,
    se_config: dict,
    pool_manager: TrajPoolManager,
    logger,
    label_prefix=None,
    source_labels=None,
    source_labels_map=None,
    operator_name=None,
):
    """
    åå¤„ç†ï¼šç”Ÿæˆ .tra æ–‡ä»¶å¹¶æ›´æ–°è½¨è¿¹æ± 
    """
    try:
        processor = TrajectoryProcessor()
        tra_stats = processor.process_iteration_directory(iter_dir)

        if tra_stats and tra_stats.get("total_tra_files", 0) > 0:
            # æå–ä¼˜åŒ–ç›®æ ‡é…ç½®
            perf_cfg_path = step_config.get("perf_base_config") or se_config.get("base_config")
            opt_target, lang_val = _extract_optimization_info(perf_cfg_path)

            # æ›´æ–° summarizer é…ç½®
            if opt_target or lang_val:
                pc = se_config.setdefault("prompt_config", {})
                if isinstance(pc, dict):
                    scfg = pc.setdefault("summarizer", {})
                    if opt_target:
                        scfg["optimization_target"] = opt_target
                    if lang_val:
                        scfg["language"] = lang_val

            _summarize_iteration_to_pool(
                iter_dir,
                iter_idx,
                pool_manager,
                se_config,
                logger,
                label_prefix=label_prefix,
                source_labels_map=source_labels_map,
                operator_name=operator_name,
            )
            try:
                mm = getattr(pool_manager, "memory_manager", None)
                if mm is not None:
                    mem = mm.load()
                    ckpt_path = Path(iter_dir) / f"memory_iter_{iter_idx}.json"
                    with open(ckpt_path, "w", encoding="utf-8") as f:
                        json.dump(mem, f, ensure_ascii=False, indent=2)
                    logger.info(f"å·²ä¿å­˜è¿­ä»£ {iter_idx} çš„è®°å¿†å¿«ç…§: {ckpt_path}")
            except Exception as e:
                logger.warning(f"ä¿å­˜è¿­ä»£ {iter_idx} è®°å¿†å¿«ç…§å¤±è´¥: {e}")
        else:
            logger.warning(f"è¿­ä»£ {iter_idx} æœªç”Ÿæˆ .tra æ–‡ä»¶")
    except Exception as e:
        logger.error(f"è¿­ä»£ {iter_idx} åå¤„ç†å¤±è´¥: {e}")


# å·²ç®€åŒ–é€»è¾‘ï¼šæœªå®Œæˆä»»åŠ¡æ—¶ç›´æ¥æ¸…ç©ºè¾“å‡ºç›®å½•å¹¶ä»å¤´å¼€å§‹ï¼Œä¸å†é€è¿­ä»£æ¸…ç†


def _print_final_summary(se_config, timestamp, log_file, output_dir, traj_pool_manager, logger):
    """
    æ‰“å°å’Œè®°å½•æœ€ç»ˆæ‰§è¡Œæ‘˜è¦
    """
    logger.info("æ‰€æœ‰ä»»åŠ¡æ‰§è¡Œå®Œæˆ")
    print("\nğŸ¯ æ‰§è¡Œå®Œæˆ")
    print(f"  æ—¥å¿—: {log_file}")
    print(f"  è¾“å‡º: {output_dir}")

    # æ±‡æ€» preds.json å¹¶ç”Ÿæˆ final.json
    try:
        root_dir = Path(output_dir)
        agg_path = aggregate_all_iterations_preds(root_dir, logger)
        if agg_path:
            write_final_json_from_preds(agg_path, root_dir, logger)
    except Exception as e:
        logger.warning(f"ç”Ÿæˆæœ€ç»ˆç»“æœæ–‡ä»¶å¤±è´¥: {e}")

    # ç»Ÿè®¡ Token
    _log_token_usage(output_dir, logger)


def _log_token_usage(output_dir, logger):
    """
    ç»Ÿè®¡å¹¶è®°å½• Token ä½¿ç”¨æƒ…å†µ
    """
    token_log_file = Path(output_dir) / "token_usage.jsonl"
    if not token_log_file.exists():
        return

    total_prompt = 0
    total_completion = 0
    total = 0
    by_context: dict[str, dict[str, int]] = {}

    try:
        with open(token_log_file, encoding="utf-8") as f:
            for line in f:
                try:
                    rec = json.loads(line)
                    pt = int(rec.get("prompt_tokens") or 0)
                    ct = int(rec.get("completion_tokens") or 0)
                    tt = int(rec.get("total_tokens") or (pt + ct))
                    ctx = str(rec.get("context") or "unknown")

                    total_prompt += pt
                    total_completion += ct
                    total += tt

                    agg = by_context.setdefault(ctx, {"prompt": 0, "completion": 0, "total": 0})
                    agg["prompt"] += pt
                    agg["completion"] += ct
                    agg["total"] += tt
                except Exception:
                    continue

        print("\nğŸ“ˆ Token ä½¿ç”¨ç»Ÿè®¡:")
        print(f"  Total: {total} (Prompt: {total_prompt}, Completion: {total_completion})")
        if by_context:
            print("  æŒ‰ä¸Šä¸‹æ–‡åˆ†ç±»:")
            for ctx, vals in by_context.items():
                print(f"    - {ctx}: prompt={vals['prompt']}, completion={vals['completion']}, total={vals['total']}")

        logger.info(
            json.dumps(
                {
                    "token_usage_total": {"prompt": total_prompt, "completion": total_completion, "total": total},
                    "by_context": by_context,
                    "token_log_file": str(token_log_file),
                },
                ensure_ascii=False,
            )
        )
    except Exception:
        pass


# --- ä¸»æµç¨‹ ---


def main():
    """
    ä¸»å‡½æ•°ï¼šç­–ç•¥é©±åŠ¨çš„ PerfAgent å¤šè¿­ä»£æ‰§è¡Œå…¥å£ã€‚
    """
    parser = argparse.ArgumentParser(description="SE æ¡†æ¶ PerfAgent å¤šè¿­ä»£æ‰§è¡Œè„šæœ¬")
    parser.add_argument("--config", default="SE/configs/se_configs/dpsk.yaml", help="SE é…ç½®æ–‡ä»¶è·¯å¾„")
    parser.add_argument("--mode", choices=["demo", "execute"], default="execute", help="è¿è¡Œæ¨¡å¼")
    args = parser.parse_args()
    cli = PerfRunCLIConfig(config=args.config, mode=args.mode)

    print("=== SE PerfAgent å¤šè¿­ä»£æ‰§è¡Œ ===")

    try:
        # 1. åŠ è½½é…ç½®
        with open(cli.config, encoding="utf-8") as f:
            se_raw = yaml.safe_load(f) or {}
        se_cfg = SEPerfRunSEConfig.from_dict(se_raw)

        # 2. å‡†å¤‡è¾“å‡ºç¯å¢ƒï¼ˆæ”¯æŒä¸å«å ä½ç¬¦çš„è·¯å¾„ä»¥ä¾¿ç»­è·‘ï¼‰
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        output_dir = se_cfg.output_dir.replace("{timestamp}", timestamp)

        # å¦‚æœ final.json å­˜åœ¨ï¼Œè®¤ä¸ºä»»åŠ¡å·²å®Œæˆï¼ˆæ­¤æ—¶ä¸æ¸…ç†ç›®å½•ï¼‰
        if (Path(output_dir) / "final.json").exists():
            log_file = setup_se_logging(output_dir)
            logger = get_se_logger("perf_run", emoji="âš¡")
            print("ğŸ‰ æ£€æµ‹åˆ°ä»»åŠ¡å·²å®Œæˆï¼Œè·³è¿‡æ‰§è¡Œ")
            logger.info("æ£€æµ‹åˆ°ä»»åŠ¡å·²å®Œæˆï¼Œç›´æ¥ç»“æŸ")
            _log_token_usage(output_dir, logger)
            return

        # æœªå®Œæˆï¼šå…ˆæ¸…ç©ºè¾“å‡ºç›®å½•ï¼Œå†åˆå§‹åŒ–æ—¥å¿—
        try:
            if Path(output_dir).exists():
                shutil.rmtree(output_dir)
            Path(output_dir).mkdir(parents=True, exist_ok=True)
        except Exception as e:
            # ç›®å½•æ¸…ç†å¤±è´¥ä»ç»§ç»­å°è¯•è¿è¡Œï¼Œä½†è®°å½•è­¦å‘Š
            print(f"æ¸…ç©ºè¾“å‡ºç›®å½•å¤±è´¥: {e}")

        log_file = setup_se_logging(output_dir)
        logger = get_se_logger("perf_run", emoji="âš¡")

        logger.info(f"å¯åŠ¨æ‰§è¡Œ: {cli.config}, æ¨¡å¼: {cli.mode}")
        logger.info(f"è¾“å‡ºç›®å½•: {output_dir}")

        # Tokenç»Ÿè®¡ä¸LLM I/Oæ—¥å¿—æ–‡ä»¶è·¯å¾„
        os.environ["SE_TOKEN_LOG_PATH"] = str(Path(output_dir) / "token_usage.jsonl")
        os.environ["SE_LLM_IO_LOG_PATH"] = str(Path(output_dir) / "llm_io.jsonl")

        # 3. åˆå§‹åŒ–æ ¸å¿ƒç»„ä»¶
        traj_pool_path = str(Path(output_dir) / "traj.pool")

        # LLM Client
        llm_client = None
        try:
            from core.utils.llm_client import LLMClient

            llm_client = LLMClient.from_se_config(se_cfg.to_dict(), use_operator_model=True)
        except Exception as e:
            logger.warning(f"LLMå®¢æˆ·ç«¯åˆå§‹åŒ–å¤±è´¥: {e}")

        # Local Memory Manager
        local_memory = None
        memory_config = se_cfg.local_memory
        if isinstance(memory_config, LocalMemoryConfig) and memory_config.enabled:
            try:
                memory_path = Path(output_dir) / "memory.json"
                local_memory = LocalMemoryManager(
                    memory_path,
                    llm_client=llm_client,
                    format_mode=memory_config.format_mode,
                )
                local_memory.initialize()
                logger.info("LocalMemoryManager å·²å¯ç”¨")
            except Exception as e:
                logger.warning(f"LocalMemoryManager åˆå§‹åŒ–å¤±è´¥: {e}")

        local_memory_text = None
        try:
            if local_memory is not None:
                mem = local_memory.load()
                local_memory_text = local_memory.render_as_markdown(mem)
        except Exception:
            local_memory_text = None

        # Trajectory Pool Manager
        traj_pool_manager = TrajPoolManager(
            traj_pool_path,
            llm_client,
            num_workers=se_cfg.num_workers,
            memory_manager=local_memory,
            prompt_config=se_cfg.prompt_config,
        )
        traj_pool_manager.initialize_pool()

        # Global Memory Manager
        global_memory = None
        global_memory_config = se_cfg.global_memory_bank
        if isinstance(global_memory_config, GlobalMemoryConfig) and global_memory_config.enabled:
            try:
                global_memory = GlobalMemoryManager(llm_client=llm_client, bank_config=global_memory_config)
                logger.info("GlobalMemoryManager å·²å¯ç”¨")
            except Exception as e:
                logger.warning(f"GlobalMemoryManager åˆå§‹åŒ–å¤±è´¥: {e}")

        # 4. æ‰§è¡Œè¿­ä»£ç­–ç•¥
        iterations = se_cfg.strategy.iterations
        logger.info(f"è®¡åˆ’æ‰§è¡Œ {len(iterations)} ä¸ªè¿­ä»£æ­¥éª¤")
        logger.info("å·²æ¸…ç†å¹¶åˆå§‹åŒ–è¾“å‡ºç›®å½•ï¼Œå‡†å¤‡ä»å¤´å¼€å§‹æ‰§è¡Œ")

        next_iteration_idx = 1

        for step_config in iterations:
            operator_name = step_config.get("operator")
            is_filter_operator = str(operator_name) in ("filter", "filter_trajectories")

            # æ„å»ºå½“å‰è¿­ä»£çš„åŸºç¡€å‚æ•°
            current_iter_dir = f"{output_dir}/iteration_{next_iteration_idx}"
            iter_params = {
                "perf_base_config": step_config.get("perf_base_config") or se_cfg.base_config,
                "operator": operator_name,
                "model": se_cfg.model.to_dict(),
                "instances_dir": se_cfg.instances.instances_dir,
                "output_dir": current_iter_dir,
                "max_iterations": se_cfg.max_iterations,
                "num_workers": se_cfg.num_workers,
            }

            try:
                if local_memory is not None:
                    _mem_latest = local_memory.load()
                    local_memory_text = local_memory.render_as_markdown(_mem_latest)
            except Exception:
                pass

            # --- åˆ†æ”¯ A: Plan ç®—å­ (ç‰¹æ®Šå¤„ç†: å±•å¼€ä¸ºå¤šå®ä¾‹é…ç½®) ---
            if operator_name == "plan":
                logger.info("æ‰§è¡Œç®—å­: Plan")
                # æ„å»º Plan ç®—å­å‚æ•°
                plan_step = {
                    "operator": "plan",
                    "num": step_config.get("num"),
                    "trajectory_labels": step_config.get("trajectory_labels"),
                }
                op_result = _execute_operator_step(plan_step, se_cfg.to_dict(), traj_pool_manager, output_dir, logger)

                plans = op_result.get("plans") or []
                for plan in plans:
                    # ä¸ºæ¯ä¸ª plan åˆ›å»ºå•ç‹¬çš„è¿­ä»£ç›®å½•
                    plan_iter_dir = f"{output_dir}/iteration_{next_iteration_idx}"
                    plan_label = plan.get("label")
                    per_inst_reqs = plan.get("per_instance_requirements") or {}

                    # å‡†å¤‡ system_prompt ç›®å½•
                    sys_prompt_dir = Path(plan_iter_dir) / "system_prompt"
                    sys_prompt_dir.mkdir(parents=True, exist_ok=True)

                    for inst_name, req in per_inst_reqs.items():
                        try:
                            data = {"prompts": {"additional_requirements": str(req)}}
                            if isinstance(local_memory_text, str) and local_memory_text.strip():
                                data["prompts"]["local_memory"] = str(local_memory_text)
                            with open(sys_prompt_dir / f"{inst_name}.yaml", "w", encoding="utf-8") as f:
                                yaml.safe_dump(data, f, allow_unicode=True, sort_keys=False)
                        except Exception:
                            pass

                    # æ³¨å…¥ Global Memory (åˆ†æ”¯ A: Plan)
                    _inject_global_memory(
                        instance_reqs=per_inst_reqs,
                        global_memory=global_memory,
                        local_memory_text=local_memory_text,
                        sys_prompt_dir=sys_prompt_dir,
                        base_config_path=step_config.get("perf_base_config") or se_cfg.base_config,
                        se_config=se_cfg.to_dict(),
                        logger=logger,
                    )

                    # æ›´æ–°è¿­ä»£å‚æ•°
                    iter_params["output_dir"] = plan_iter_dir
                    iter_params["operator_params"] = {"instance_templates_dir": str(sys_prompt_dir)}

                    print(f"\n=== è¿­ä»£ {next_iteration_idx} (Plan: {plan_label}) ===")
                    os.environ["SE_ITERATION_INDEX"] = str(next_iteration_idx)

                    # æ‰§è¡Œ PerfAgent
                    run_result = call_perfagent(iter_params, logger, dry_run=(cli.mode == "demo"))

                    # åå¤„ç†ï¼šç”Ÿæˆè½¨è¿¹
                    if run_result.get("status") == "success" and cli.mode == "execute":
                        _process_and_summarize(
                            Path(plan_iter_dir),
                            next_iteration_idx,
                            step_config,
                            se_cfg.to_dict(),
                            traj_pool_manager,
                            logger,
                            label_prefix=plan_label,
                            operator_name=operator_name,
                        )

                    next_iteration_idx += 1
                continue

            # --- åˆ†æ”¯ B: æ™®é€šç®—å­æˆ–æ— ç®—å­ ---
            initial_code_dir = None
            instance_templates_dir = None
            source_labels_map = None

            if operator_name:
                logger.info(f"æ‰§è¡Œç®—å­: {operator_name}")

                # å‡†å¤‡ç®—å­è¾“å…¥
                src_labels = []
                if isinstance(step_config.get("source_trajectories"), list):
                    src_labels = [str(x) for x in step_config.get("source_trajectories")]
                elif step_config.get("source_trajectory"):
                    src_labels = [str(step_config.get("source_trajectory"))]

                op_step_config = {
                    "operator": operator_name,
                    "inputs": [{"label": l} for l in src_labels],
                    "outputs": [{"label": str(step_config.get("trajectory_label"))}]
                    if step_config.get("trajectory_label")
                    else [],
                    "strategy": step_config.get("filter_strategy") or step_config.get("strategy") or {},
                }

                op_result = _execute_operator_step(
                    op_step_config, se_cfg.to_dict(), traj_pool_manager, current_iter_dir, logger
                )

                initial_code_dir = op_result.get("initial_code_dir")
                instance_templates_dir = op_result.get("instance_templates_dir")
                source_labels_map = op_result.get("source_entry_labels_per_instance")

                # Filter ç®—å­ç‰¹æ®Šé€»è¾‘ï¼šè·³è¿‡ PerfAgent æ‰§è¡Œ
                if is_filter_operator:
                    logger.info("Filter ç®—å­æ‰§è¡Œå®Œæ¯•ï¼Œè·³è¿‡åç»­ PerfAgent è¿è¡Œ")
                    continue

                if isinstance(local_memory_text, str) and local_memory_text.strip():
                    try:
                        if instance_templates_dir:
                            p = Path(instance_templates_dir)
                            if p.exists():
                                for fp in p.glob("*.yaml"):
                                    try:
                                        with open(fp, encoding="utf-8") as f:
                                            d = yaml.safe_load(f) or {}
                                        pm = d.get("prompts") or {}
                                        pm["local_memory"] = str(local_memory_text)
                                        d["prompts"] = pm
                                        with open(fp, "w", encoding="utf-8") as f:
                                            yaml.safe_dump(d, f, allow_unicode=True, sort_keys=False)
                                    except Exception:
                                        pass
                        else:
                            sys_prompt_dir = Path(current_iter_dir) / "system_prompt"
                            sys_prompt_dir.mkdir(parents=True, exist_ok=True)
                            inst_dir = Path(iter_params.get("instances_dir") or "")
                            for fp in inst_dir.glob("*.json"):
                                try:
                                    with open(sys_prompt_dir / f"{fp.stem}.yaml", "w", encoding="utf-8") as f:
                                        data = {"prompts": {"local_memory": str(local_memory_text)}}
                                        yaml.safe_dump(data, f, allow_unicode=True, sort_keys=False)
                                except Exception:
                                    pass
                            instance_templates_dir = str(sys_prompt_dir)
                    except Exception:
                        pass

                # æ³¨å…¥ Global Memory (åˆ†æ”¯ B: æ™®é€šç®—å­)
                # å³ä½¿æ²¡æœ‰ local_memory_textï¼Œä¹Ÿå¯èƒ½éœ€è¦ global_memory
                # éœ€è¦æ„é€  instance_reqsï¼Œå¦‚æœæ²¡æœ‰ç°æˆçš„ yamlï¼Œå¯ä»¥å°è¯•ä» instance_templates_dir è¯»å–
                # æˆ–è€…éå† instances_dir

                try:
                    target_sys_prompt_dir = None
                    if instance_templates_dir:
                        target_sys_prompt_dir = Path(instance_templates_dir)
                    else:
                        # å¦‚æœè¿˜æ²¡åˆ›å»ºç›®å½•ï¼Œå°±åˆ›å»º
                        target_sys_prompt_dir = Path(current_iter_dir) / "system_prompt"
                        target_sys_prompt_dir.mkdir(parents=True, exist_ok=True)
                        instance_templates_dir = str(target_sys_prompt_dir)  # ç¡®ä¿å›å¡«

                    # æ”¶é›†å½“å‰æ‰€æœ‰çš„å®ä¾‹åå’Œ reqs
                    # å¦‚æœæœ‰ç°æˆçš„ yamlï¼Œè¯»å– reqsï¼›å¦åˆ™ reqs ä¸ºç©º
                    inst_reqs_map = {}

                    # 1. å°è¯•ä» instance_templates_dir è¯»å–ç°æœ‰ yaml
                    if target_sys_prompt_dir and target_sys_prompt_dir.exists():
                        for fp in target_sys_prompt_dir.glob("*.yaml"):
                            try:
                                with open(fp, encoding="utf-8") as f:
                                    d = yaml.safe_load(f) or {}
                                    req = d.get("prompts", {}).get("additional_requirements", "")
                                    inst_reqs_map[fp.stem] = req
                            except Exception:
                                pass

                    # 2. å¦‚æœ map ä¸ºç©ºï¼ˆå³è¿˜æ²¡æœ‰ yaml æ–‡ä»¶ï¼‰ï¼Œåˆ™éå† instances_dir åˆå§‹åŒ– key
                    if not inst_reqs_map:
                        inst_dir = Path(iter_params.get("instances_dir") or "")
                        if inst_dir.exists():
                            for fp in inst_dir.glob("*.json"):
                                inst_reqs_map[fp.stem] = ""  # é»˜è®¤ä¸ºç©º

                    _inject_global_memory(
                        instance_reqs=inst_reqs_map,
                        global_memory=global_memory,
                        local_memory_text=local_memory_text,
                        sys_prompt_dir=target_sys_prompt_dir,
                        base_config_path=step_config.get("perf_base_config") or se_cfg.base_config,
                        se_config=se_cfg.to_dict(),
                        logger=logger,
                    )
                except Exception as e:
                    logger.warning(f"Global Memory æ³¨å…¥æµç¨‹å¼‚å¸¸: {e}")

            # è®¾ç½®ç®—å­è¾“å‡ºå‚æ•°
            iter_params["operator_params"] = {}
            if initial_code_dir:
                iter_params["operator_params"]["initial_code_dir"] = initial_code_dir
            if instance_templates_dir:
                iter_params["operator_params"]["instance_templates_dir"] = instance_templates_dir

            print(f"\n=== è¿­ä»£ {next_iteration_idx} ===")
            os.environ["SE_ITERATION_INDEX"] = str(next_iteration_idx)

            # æ‰§è¡Œ PerfAgent
            run_result = call_perfagent(iter_params, logger, dry_run=(cli.mode == "demo"))

            # åå¤„ç†
            if run_result.get("status") == "success" and cli.mode == "execute":
                # ç¡®å®šæºæ ‡ç­¾ç”¨äºè®°å½•
                src_labels_for_summary = []
                if isinstance(step_config.get("source_trajectories"), list):
                    src_labels_for_summary = [str(x) for x in step_config.get("source_trajectories")]

                _process_and_summarize(
                    Path(current_iter_dir),
                    next_iteration_idx,
                    step_config,
                    se_cfg.to_dict(),
                    traj_pool_manager,
                    logger,
                    label_prefix=step_config.get("trajectory_label"),
                    source_labels=src_labels_for_summary,
                    source_labels_map=source_labels_map,
                    operator_name=operator_name,
                )

            next_iteration_idx += 1

        # Update global memory
        if global_memory:
            global_memory.update_from_pool(traj_pool_manager)

        # 5. æœ€ç»ˆæ±‡æ€»
        _print_final_summary(se_cfg.to_dict(), timestamp, log_file, output_dir, traj_pool_manager, logger)

    except Exception as e:
        if "logger" in locals():
            logger.error(f"ç¨‹åºè¿è¡Œå¼‚å¸¸: {e}", exc_info=True)
        print(f"ç¨‹åºè¿è¡Œå¼‚å¸¸: {e}")
        sys.exit(1)


if __name__ == "__main__":
    main()
